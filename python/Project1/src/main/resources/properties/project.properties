# GENERAL DIRECTORIES
LOGS_DIR=$BASE_DIR/logs
CODE_DIR=$BASE_DIR/src/main/resources/code
PROPERTIES_DIR=$BASE_DIR/src/main/resources/properties
INPUT_DIRECTORY=$BASE_DIR/files/input_files
OUTPUT_DIRECTORY=$BASE_DIR/files/output_files

# PYTHON SCRIPT
PYTHON_SCRIPT_NAME=project1.py
PROJECT_SCRIP=$CODE_DIR/$PYTHON_SCRIPT_NAME

# LOG4J DIRECTORY
LOG4J_DIR=$PROPERTIES_DIR/log4j.properties

# LOGS OUTPUT DIRECTORIES
LOG_OUTPUT=$LOGS_DIR/output
LOG_SPARK=$LOGS_DIR/spark

# LOGS FILENAMES
TIMESTAMP=$(date +"%Y-%m-%d_%H:%M:%S")
LOG_FILE=project1-$TIMESTAMP.log
SPARK_LOG_PATH=$LOG_SPARK/$LOG_FILE
OUTPUT_LOG_PATH=$LOG_OUTPUT/$LOG_FILE

# INPUT CSV FILE
IRIS_CSV_NAME=iris.csv
INPUT_CSV_IRIS=$INPUT_DIRECTORY/$IRIS_CSV_NAME

# OUTPUT PARQUETS PATH
OUTPUT_PARQUET_PATH=$OUTPUT_DIRECTORY/iris

# ENVIRONMENT VARIABLES
CONDA_PREFIX=/home/david/anaconda3/envs/pyspark_env
SPARK_HOME=/opt/spark
PYSPARK_PYTHON=$CONDA_PREFIX/bin/python
JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

# CONDA ROUTES
CONDA_SHELL=/home/david/anaconda3/etc/profile.d/conda.sh
CONDA_ENVIROMENT=pyspark_env